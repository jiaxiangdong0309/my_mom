# AI 知识记忆库 - 技术选型文档

**版本**: v1.0
**日期**: 2025-12-24
**文档状态**: 待评审
**编写人**: 技术选型组

---

## 1. 文档概述

### 1.1 文档目的

本文档旨在为「AI 知识记忆库」项目提供技术选型决策依据，通过对比分析不同技术方案的优劣，确定最终的技术栈，为后续设计和开发提供指导。

### 1.2 项目定位

一款为 AI 编辑器用户提供的知识记忆与检索工具，核心能力包括：
- 结构化知识存储
- 语义搜索与全文检索
- 跨会话、跨编辑器经验复用
- 本地部署、隐私优先

### 1.3 团队技术储备

- **后端**: Python（熟悉）
- **前端**: HTML、React、Vue（熟悉）
- **AI/ML**: 有基础，需调研向量数据库相关技术

---

## 2. 选型原则

| 原则 | 优先级 | 说明 |
|------|--------|------|
| **团队匹配度** | P0 | 优先选择团队熟悉或学习成本低的技术栈 |
| **部署简单** | P0 | 本地运行，无需复杂的基础设施依赖 |
| **性能满足** | P1 | MVP 阶段响应速度 < 500ms |
| **可扩展性** | P2 | 预留 v2.0 扩展空间（多用户、知识图谱） |
| **开源生态** | P1 | 优先选择成熟的开源方案，避免厂商锁定 |
| **隐私友好** | P0 | 数据本地存储，不上云 |

---

## 3. 技术选型

### 3.1 编程语言与运行时

#### 候选方案

| 方案 | 优势 | 劣势 | 评分 |
|------|------|------|------|
| **Python** | 团队熟悉、AI 生态丰富、异步支持好 | 运行时性能较慢 | ⭐⭐⭐⭐⭐ |
| Node.js | npm 生态好、适合 CLI 工具 | 团队不熟悉 | ⭐⭐⭐ |
| Go | 性能极佳、单文件部署简单 | 学习成本高、AI 库少 | ⭐⭐ |

#### 决策分析

**选择 Python 的核心理由：**

1. **团队现有技能**：团队成员熟悉 Python，可快速上手
2. **AI 生态成熟**：ChromaDB、LangChain、Ollama 等 AI 工具均原生支持 Python
3. **异步框架成熟**：FastAPI 提供高性能异步 API 服务
4. **打包方案成熟**：PyInstaller 可打包为单文件可执行程序

#### 最终选型

**✅ Python 3.11+**

- 理由：团队匹配度最高，AI 工具链最完善
- 性能缓解：异步 I/O + C 扩展库（如 better-sqlite3 的 Python 绑定）

---

### 3.2 Web 框架

#### 候选方案

| 方案 | 优势 | 劣势 | 学习成本 |
|------|------|------|----------|
| **FastAPI** | 自动生成 OpenAPI 文档、原生异步、类型验证 | 相对较新 | 低 |
| Flask | 轻量、生态成熟 | 异步支持弱、需手动文档 | 低 |
| Django | 功能完整、ORM 强大 | 过重、异步支持差 | 中 |

#### 决策分析

**FastAPI vs Flask：**

| 维度 | FastAPI | Flask |
|------|---------|-------|
| 异步支持 | ✅ 原生 | ⚠️ 需扩展 |
| API 文档 | ✅ 自动生成（Swagger/ReDoc） | ❌ 手动维护 |
| 类型检查 | ✅ Pydantic 自动验证 | ⚠️ 需手动 |
| 性能 | ⚡ 快（Starlette） | 🐢 较慢 |
| 生态 | 🟢 成长中 | 🟢 成熟 |

**实际测试数据（参考）：**
- FastAPI：~3500 req/s（简单 JSON 响应）
- Flask：~1200 req/s（同等条件）

#### 最终选型

**✅ FastAPI 0.109+**

- 理由：异步性能优秀、自动生成 API 文档、降低前后端联调成本
- 依赖：Uvicorn 作为 ASGI 服务器

---

### 3.3 数据库方案

#### 3.3.1 结构化数据存储

| 方案 | 优势 | 劣势 | 适用场景 |
|------|------|------|----------|
| **SQLite** | 单文件、零配置、本地优先 | 并发写入弱 | 单用户 MVP |
| PostgreSQL | 功能强大、并发优秀 | 需独立部署 | 多用户 v2.0 |
| DuckDB | 分析性能强 | 生态较新 | 数据分析场景 |

**决策：✅ SQLite**

- 理由：单用户场景无需并发、文件便携、易于备份
- 扩展：配合 SQLAlchemy ORM，降低 SQL 维护成本

#### 3.3.2 向量数据库

这是本次选型的**核心决策点**，直接影响搜索性能和架构复杂度。

| 方案 | 优势 | 劣势 | 部署复杂度 | Python 原生 |
|------|------|------|-----------|------------|
| **ChromaDB** | AI 原生、API 友好、持久化简单 | 元数据查询弱 | 🟢 低 | ✅ |
| **sqlite-vec** | 集成度高、单文件 | 需编译 C 扩展 | 🟡 中 | ❌ |
| **Qdrant** | 性能极佳、过滤能力强 | 需独立服务 | 🟠 高 | ✅ |
| **FAISS** | Meta 出品、性能最快 | 无元数据、需手动维护 | 🟡 中 | ✅ |

#### 详细对比

##### **ChromaDB**
```
优势：
✅ 专为 AI 应用设计，API 非常简洁
✅ pip install 即可，无额外依赖
✅ 支持持久化到磁盘
✅ 内置 HNSW 索引，检索速度快
✅ Python 原生，文档丰富

劣势：
⚠️ 元数据查询能力弱（无法做复杂 JOIN）
⚠️ 大规模数据性能未验证（>100万条）
```

##### **sqlite-vec**
```
优势：
✅ 与 SQLite 深度集成，单文件存储
✅ 无需独立向量服务
✅ 支持 SQL 查询，灵活度高

劣势：
❌ 需编译 C 扩展，Windows 安装困难
❌ Python 绑定不完善
❌ 社区较小，问题排查难
```

##### **Qdrant**
```
优势：
✅ 性能极佳（Rust 编写）
✅ 过滤器能力强（支持复杂 WHERE）
✅ Docker 部署简单

劣势：
❌ 需独立运行服务（增加部署复杂度）
❌ 单用户场景过重
```

#### 决策：✅ ChromaDB + SQLite 双库方案

**架构设计：**
- **ChromaDB**: 存储向量数据，负责语义检索
- **SQLite**: 存储结构化数据（元数据、标签、时间），负责复杂查询

**为什么不用单一方案？**
- ChromaDB 擅长向量检索，但元数据查询弱（如 `GROUP BY tags` 统计）
- SQLite 擅长关系查询，但不支持向量
- **各取所长**：向量检索用 Chroma，标签过滤用 SQLite JOIN

**数据同步策略：**
- Chroma 元数据中存储 `memory_id` 作为关联键
- 搜索时先用 SQLite 过滤（标签、时间），再用 Chroma 检索

---

### 3.4 ORM 与数据库操作

| 方案 | 优势 | 劣势 | 学习成本 |
|------|------|------|----------|
| **SQLAlchemy** | 功能强大、生态成熟、类型提示好 | API 复杂 | 中 |
| Tortoise ORM | 异步原生、类 Django ORM | 生态较新 | 低 |
| **原生 SQL** | 简单直接、性能最优 | 无类型安全、维护成本高 | 低 |

**决策：✅ SQLAlchemy 2.0（异步模式）**

- 理由：类型提示完善、团队熟悉、生态成熟
- 使用 `AsyncSession` 配合 FastAPI 异步请求

---

### 3.5 异步任务队列

向量化任务需要异步处理（响应时间 2-5s，不能阻塞 API）。

| 方案 | 优势 | 劣势 | 复杂度 |
|------|------|------|--------|
| **内存队列（自研）** | 零依赖、简单 | 进程重启丢失任务、无监控 | 🟢 低 |
| **Celery + Redis** | 成熟、可靠、支持重试 | 需额外部署 Redis | 🟠 中 |
| **RQ (Redis Queue)** | 轻量、简单 | 功能较弱 | 🟡 中 |
| **asyncio.Queue** | 原生异步、无需依赖 | 仅单进程 | 🟢 低 |

#### 决策分析

**MVP 阶段：✅ asyncio.Queue（内存队列）**
- 理由：零依赖、够用、降低部署复杂度
- 风险：进程崩溃丢失任务（可接受，用户可手动重试）

**v2.0 升级路径：**
- 数据量 > 1000 条 → 升级到 Celery + Redis
- 持久化任务 + 失败重试 + 监控面板

---

### 3.6 Embedding 服务

#### 本地模型方案

| 模型 | 大小 | 维度 | 速度 | 质量 | 部署复杂度 | 推荐度 |
|------|------|------|------|------|-----------|--------|
| **BAAI/bge-small-zh-v1.5** (sentence-transformers) | **80MB** | 512 | 很快 | 高 | 🟢 pip install 即可 | ⭐⭐⭐⭐⭐ |
| nomic-embed-text (Ollama) | 276MB | 768 | 快 | 高 | 🟡 需启动服务 | ⭐⭐⭐ |
| bge-small-zh-v1.5 | 300MB+ | 512 | 中 | 高 | 🟢 pip install 即可 | ⭐⭐⭐⭐ |
| all-mpnet-base-v2 | 420MB | 768 | 慢 | 极高 | 🟢 pip install 即可 | ⭐⭐⭐ |

**决策：✅ BAAI/bge-small-zh-v1.5（sentence-transformers 部署）**

**理由：**
1. **零启动成本**：`pip install sentence-transformers` 即可，无需额外服务
2. **体积最小**：80MB，下载快速
3. **Python 原生**：直接在代码中调用，无 HTTP 开销
4. **质量更优**：512 维能提供更精准的语义表达
5. **易于升级**：后期可无缝切换到更大的模型

**代码示例：**
```python
from sentence_transformers import SentenceTransformer

# 首次运行自动下载模型（80MB）
model = SentenceTransformer('BAAI/bge-small-zh-v1.5')

# 直接生成向量
embedding = model.encode("我昨天怎么修复内存泄露的？")
print(embedding.shape)  # (512,)
```

#### 远程 API 方案（备选）

| 服务 | 免费额度 | 速度 | 质量 | 推荐 |
|------|---------|------|------|------|
| **Jina AI** | 100万 tokens/月 | 快 | 高 | ⭐⭐⭐⭐⭐ |
| HuggingFace Inference | 有限 | 慢 | 中 | ⭐⭐⭐ |
| OpenAI embeddings | 无 | 快 | 极高 | ⭐⭐⭐（付费）|

**决策：✅ Jina AI（作为远程备选）**
- 理由：免费 tier 慷慨、无需信用卡、API 简单

#### 最终方案

**双模式支持（用户可配置）：**
```python
# 本地模式（默认，推荐）
sentence-transformers + BAAI/bge-small-zh-v1.5
  → 80MB、零依赖、隐私保护、速度最快

# 远程模式（可选）
Jina AI + jina-embeddings-v2-base-en
  → 更高质量、需联网、免费 tier

# 升级路径（v2.0）
bge-small-zh-v1.5（中文优化）或 all-mpnet-base-v2（更高精度）
```

---

### 3.7 内容分段（Token 处理）

Embedding API 有 token 限制（如 OpenAI 8191 tokens），长内容需分段。

| 方案 | 优势 | 劣势 |
|------|------|------|
| **按段落分段** | 保持语义完整 | 段落长度不均 |
| 固定长度切分 | 长度均匀 | 可能切断语义 |
| 递归切分 | 平衡二者 | 实现复杂 |

**决策：✅ 按段落分段（智能切分）**

- 策略：以 `\n\n` 为分隔符，单段超 500 tokens 则强制切分
- 依赖：`tiktoken` 精确计算 tokens
- 语义保证：优先保持段落完整

---

### 3.8 前端方案

#### 候选方案

| 方案 | 优势 | 劣势 | 开发效率 |
|------|------|------|----------|
| **原生 HTML + Vanilla JS** | 零构建、单文件 | 大型项目维护难 | 🟡 中 |
| React SPA | 组件化、团队熟悉 | 需构建步骤 | 🟢 高 |
| Vue SPA | 简单、团队熟悉 | 需构建步骤 | 🟢 高 |

#### 决策分析

**MVP 阶段特点：**
- 页面数量少（1-2 个）
- 交互简单（列表 + 搜索 + 删除）
- 团队熟悉 React/Vue

**对比：**

| 维度 | 原生 HTML | React/Vue |
|------|----------|-----------|
| 部署 | ✅ 单文件，无需构建 | ⚠️ 需打包流程 |
| 开发速度 | 🐢 慢（无组件化） | ⚡ 快（团队熟悉） |
| 维护性 | ⚠️ 代码耦合 | ✅ 组件化 |
| 性能 | ⚡ 快（无框架） | 🐢 稍慢（但可接受）|

**决策：✅ React SPA（Vite 构建）**

**理由：**
1. **团队熟悉**：团队已有 React 经验，开发效率高
2. **类型安全**：配合 TypeScript 降低 bug 率
3. **生态成熟**：UI 组件库（Ant Design / Shadcn）提升开发速度
4. **v2.0 扩展**：统计图表、知识图谱等复杂功能更易实现

**打包策略：**
- 开发环境：Vite dev server（热更新）
- 生产构建：`npm run build` → 静态文件嵌入 Python 项目
- FastAPI 静态文件服务：`app.mount("/", StaticFiles(directory="dist"))`

---

### 3.9 CLI 框架

#### 候选方案

| 方案 | 优势 | 劣势 |
|------|------|------|
| **Typer** | 类型安全、自动生成帮助、美观 | 需 Python 3.7+ |
| Click | 成熟、生态大 | 类型提示弱 |
| argparse | 标准库、无需安装 | 手动维护帮助 |

**决策：✅ Typer**

- 理由：现代 CLI 框架、自动生成 `--help`、支持异步命令
- 配合 Rich 美化输出（进度条、表格）

---

### 3.10 打包与分发

| 方案 | 优势 | 劣势 |
|------|------|------|
| **PyInstaller** | 成熟、跨平台、单文件 | 体积大（~50MB） |
| Nuitka | 编译为 C，性能好 | 配置复杂 |
| cx_Freeze | 轻量 | 平台兼容性差 |

**决策：✅ PyInstaller**

- 理由：社区标准、配置简单、一次打包多平台
- 优化：使用 `--onefile` 生成单文件可执行程序

**分发策略：**
1. **GitHub Releases**: 发布编译好的二进制文件（Windows/macOS/Linux）
2. **PyPI**: `pip install ai-memory-hub`（需 Python 环境）
3. **Docker**: 可选，面向高级用户

---

## 4. 最终技术栈汇总

### 4.1 技术栈全景图

```
┌─────────────────────────────────────────────────────────────┐
│                        前端层                                │
│  React 18 + TypeScript + Vite + Tailwind CSS + Ant Design  │
└──────────────────────────┬──────────────────────────────────┘
                           │ HTTP/JSON
                           ▼
┌─────────────────────────────────────────────────────────────┐
│                      API 服务层                              │
│                   FastAPI + Uvicorn                         │
└──────────────────────────┬──────────────────────────────────┘
                           │
         ┌─────────────────┼─────────────────┐
         ▼                 ▼                 ▼
┌──────────────┐  ┌──────────────┐  ┌──────────────┐
│   业务逻辑   │  │  异步任务    │  │  Embedding   │
│  SQLAlchemy  │  │ asyncio.Queue│  │ sent-trans/J │
└──────┬───────┘  └──────────────┘  └──────────────┘
       │
       ▼
┌──────────────┐     ┌──────────────┐
│   SQLite     │     │  ChromaDB    │
│ (结构化数据) │     │  (向量数据)  │
└──────────────┘     └──────────────┘
```

### 4.2 技术栈清单

| 层级 | 技术选型 | 版本 | 用途 |
|------|---------|------|------|
| **语言** | Python | 3.11+ | 运行时 |
| **Web 框架** | FastAPI | 0.109+ | API 服务 |
| **ASGI 服务器** | Uvicorn | 0.27+ | 运行 FastAPI |
| **数据库（结构化）** | SQLite | 3.40+ | 元数据存储 |
| **ORM** | SQLAlchemy | 2.0+ | 数据库操作 |
| **向量数据库** | ChromaDB | 0.4.22+ | 向量存储与检索 |
| **异步队列** | asyncio.Queue | 内置 | 任务队列（MVP）|
| **Embedding 本地** | sentence-transformers | 2.2+ | 本地向量化 |
| **Embedding 模型** | BAAI/bge-small-zh-v1.5 | 80MB | 向量模型（512维）|
| **Embedding 远程** | Jina AI | - | 备选方案 |
| **前端框架** | React | 18+ | UI |
| **前端语言** | TypeScript | 5+ | 类型安全 |
| **构建工具** | Vite | 5+ | 打包构建 |
| **UI 组件库** | Ant Design | 5+ | 组件 |
| **样式方案** | Tailwind CSS | 3+ | 原子化 CSS |
| **CLI 框架** | Typer | 0.9+ | 命令行 |
| **CLI 美化** | Rich | 13+ | 终端输出 |
| **Token 计算** | tiktoken | 0.5+ | 内容分段 |
| **打包工具** | PyInstaller | 6+ | 可执行文件 |

---

## 5. 架构决策记录（ADR）

### ADR-001: 为什么选择 ChromaDB 而非 sqlite-vec？

**背景**：需要向量数据库支持语义检索

**决策**：选择 ChromaDB

**理由**：
1. Python 原生，`pip install` 即可，无需编译 C 扩展
2. API 设计简洁，专为 AI 应用优化
3. 文档丰富，社区活跃（GitHub 30k+ stars）
4. 与 SQLAlchemy 配合，实现双库架构，各取所长

**后果**：
- ✅ 开发效率高，学习成本低
- ⚠️ 需维护两套数据存储（Chroma + SQLite）
- ⚠️ 数据同步需应用层保证

**撤销条件**：
- ChromaDB 出现严重性能问题（> 1s 检索延迟）
- ChromaDB 项目停止维护

---

### ADR-002: 为什么 MVP 使用内存队列而非 Celery？

**背景**：向量化任务需异步处理，避免阻塞 API

**决策**：MVP 使用 `asyncio.Queue`，v2.0 升级 Celery

**理由**：
1. 降低部署复杂度（无需 Redis）
2. MVP 阶段任务量小（< 100 条/天），内存队列足够
3. 零依赖，减少故障点

**后果**：
- ✅ 部署简单，用户开箱即用
- ⚠️ 进程崩溃丢失任务（可接受，用户可手动重试）
- ⚠️ 无任务监控面板

**升级触发条件**：
- 日均存储 > 1000 条
- 用户反馈任务丢失频率高
- 需要任务监控和失败重试

---

### ADR-003: 为什么前端选择 React 而非原生 HTML？

**背景**：团队熟悉 React，但 MVP 页面简单

**决策**：使用 React + Vite

**理由**：
1. **团队效率**：团队已有 React 经验，开发速度更快
2. **类型安全**：TypeScript + React 降低 bug 率
3. **可扩展性**：v2.0 统计图表、知识图谱等功能更易实现
4. **组件复用**：Ant Design 等组件库提升开发效率

**后果**：
- ✅ 开发效率高，代码可维护性强
- ⚠️ 需构建步骤（但 Vite 很快）
- ⚠️ 打包体积稍大（可接受）

---

## 6. 风险评估

### 6.1 技术风险

| 风险 | 概率 | 影响 | 应对措施 |
|------|------|------|----------|
| **ChromaDB 性能瓶颈** | 中 | 高 | 性能测试验证，保留切换到 Qdrant 的选项 |
| **Ollama 首次启动慢** | 高 | 低 | 文档提示，后台预加载 |
| **长内容分段质量差** | 中 | 中 | 优先按段落分段，测试调优 |
| **SQLite 并发锁** | 低 | 中 | 单用户场景问题不大，v2.0 考虑 PostgreSQL |
| **PyInstaller 打包失败** | 中 | 中 | 提前验证各平台打包流程 |

### 6.2 业务风险

| 风险 | 概率 | 影响 | 应对措施 |
|------|------|------|----------|
| **Embedding API 费用超预期** | 低 | 中 | MVP 默认本地模型，远程为可选 |
| **用户存储敏感信息** | 高 | 低 | 文档提示，v2.0 增加自动脱敏 |
| **数据丢失** | 低 | 高 | 提供导出/备份功能 |

### 6.3 团队风险

| 风险 | 概率 | 影响 | 应对措施 |
|------|------|------|----------|
| **ChromaDB 学习曲线** | 中 | 低 | 官方文档完善，预留学习时间 |
| **异步编程复杂度** | 中 | 中 | FastAPI + SQLAlchemy 异步模式有文档支持 |

---

## 7. 技术债务与后续演进

### 7.1 MVP 已知限制

| 限制 | 影响 | 计划解决版本 |
|------|------|-------------|
| 无任务持久化 | 进程重启丢失任务 | v1.1（升级 Celery） |
| 无数据备份 | 误删无法恢复 | v1.1（导出/备份） |
| 无内容编辑 | 存储后无法修改 | v2.0 |
| 无用户认证 | 单用户 | v2.0（多用户） |

### 7.2 v2.0 技术演进路线

#### 数据存储升级
```
SQLite → PostgreSQL（多用户、高并发）
内存队列 → Celery + Redis（任务持久化）
ChromaDB → Qdrant（性能优化，可选）
```

#### 功能扩展
```
单体服务 → 微服务（分离向量服务）
本地部署 → Docker + Docker Compose
单用户 → 多用户租户
```

---

## 8. 依赖库版本策略

### 8.1 核心依赖锁定

```txt
# requirements.txt（生产环境）
fastapi==0.109.0
uvicorn[standard]==0.27.0
sqlalchemy==2.0.25
chromadb==0.4.22
sentence-transformers==2.2.2
tiktoken==0.5.2
typer[all]==0.9.0
rich==13.7.0
httpx==0.26.0
pydantic==2.5.3
pydantic-settings==2.1.0
```

### 8.2 版本管理策略

- **主版本锁定**：生产环境锁定主版本（如 `==2.0.25`）
- **开发环境**：允许小版本更新（如 `~=2.0.0`）
- **定期更新**：每季度评估依赖更新，关注安全补丁

---

## 9. 性能基线与验收标准

### 9.1 性能指标

| 指标 | 目标 | 测量方法 |
|------|------|----------|
| **存储响应时间** | < 100ms（不含向量化） | Apache Bench |
| **搜索响应时间** | < 500ms（Top 3） | 向量检索 + SQL 查询 |
| **Web UI 首屏** | < 1s | Lighthouse |
| **内存占用** | < 200MB（空闲） | psutil |
| **启动时间** | < 3s | time 命令 |

### 9.2 容量规划

| 指标 | MVP 目标 | v2.0 目标 |
|------|----------|----------|
| 最大记录数 | 10,000 条 | 100,000 条 |
| 并发用户 | 1 人 | 10 人 |
| 存储空间 | 100MB | 1GB |

---

## 10. 附录

### 10.1 参考资料

| 资源 | 链接 |
|------|------|
| ChromaDB 官方文档 | https://docs.trychroma.com/ |
| FastAPI 官方教程 | https://fastapi.tiangolo.com/ |
| SQLAlchemy 2.0 文档 | https://docs.sqlalchemy.org/en/20/ |
| Ollama 官网 | https://ollama.com/ |
| Jina AI Embeddings | https://jina.ai/embeddings |

### 10.2 技术选型评审记录

| 日期 | 评审人 | 决策 | 备注 |
|------|--------|------|------|
| 2025-12-24 | 技术团队 | 确认 Python + FastAPI + ChromaDB 方案 | 需性能验证 |

---

**文档结束**

如有疑问或需要补充，请随时提出。
